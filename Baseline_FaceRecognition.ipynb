{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline-FaceRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqA5poQeSL93gaXveR7DKB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4HxRq9KLzjv",
        "outputId": "44c40f00-775a-4428-c808-f540ecb18681"
      },
      "source": [
        "! pip install deepface\n",
        "from deepface import DeepFace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.68-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.5-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.5)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.7.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.19.5)\n",
            "Collecting gdown>=3.10.1\n",
            "  Downloading gdown-4.2.0.tar.gz (13 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.4)\n",
            "Collecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.62.3)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.22.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.12.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.42.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.9.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.2.0-py3-none-any.whl size=14273 sha256=b1e041214ea8a3aae9bb6158137e3663761b80572d48d3131d821dc802356bac\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/17/ff/58721d1fabdb87c21a0529948cf39e2be9af90ddbe4ad65944\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown, retina-face, mtcnn, deepface\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed deepface-0.0.68 gdown-4.2.0 mtcnn-0.1.1 retina-face-0.0.5\n",
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iBnWPONL41g"
      },
      "source": [
        "import numpy as np\n",
        "from os import listdir\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ShMX2cM0Md",
        "outputId": "e49ec0af-112d-4a10-9e4d-43ffd374753b"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlxSiHaJQ0ON"
      },
      "source": [
        "def FaceRecognizer(filename1,filename2):\n",
        "  folder = './gdrive/MyDrive/Final_Test/'\n",
        "  # path\n",
        "  filenameTest = folder + filename1\n",
        "  filenameVerify= folder + filename2\n",
        "  if filename2.find(\"j2k_r\") == -1 and filename2.find(\"j2k\") == -1:\n",
        "    TypeOfTest='normal'\n",
        "  else:\n",
        "    if(filename2.find(\"j2k_r\") == -1):\n",
        "          TypeOfTest='hardEncrypted'\n",
        "    else:\n",
        "          TypeOfTest='lowEncrypted'\n",
        "\n",
        "  detected=DeepFace.verify(img1_path=filenameTest,img2_path=filenameVerify,model_name='Facenet',enforce_detection=False)\n",
        "  if(filename1.split('_')[0] ==  filename2.split('_')[0]):\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,1,detected['distance'],'same')\n",
        "    else:\n",
        "          return (TypeOfTest,-1,0,'same')\n",
        "  else:\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,-1,0,'different')\n",
        "    else:\n",
        "          return (TypeOfTest,1,detected['distance'],'different')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9aP2tyVL57e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a69768-f6c3-4967-963c-b4975e8b10cf"
      },
      "source": [
        "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
        "# specify folder to plot\n",
        "filename1_normal='501194_490544.jpg'\n",
        "filename2_normal='501195_490571.jpg'\n",
        "array_test_images=[filename1_normal,filename2_normal]\n",
        "folder = './gdrive/MyDrive/Final_Test/'\n",
        "i = 1\n",
        "x_axis=0\n",
        "normal_y_axis=0\n",
        "lowEncrypted_y_axis=0\n",
        "distances_normal=0\n",
        "distances_normal_different=0\n",
        "distances_lowEncrypted=0\n",
        "distances_lowEncrypted_different=0\n",
        "highEncrypted_y_axis=0\n",
        "distances_highEncrypted=0\n",
        "distances_highEncrypted_different=0\n",
        "for testFile in array_test_images:\n",
        "    # enumerate files\n",
        "  for filename in listdir(folder):\n",
        "    # get prediction\n",
        "    if(filename != '.ipynb_checkpoints'):\n",
        "      [TypeOfTest,value,distance,sameOrDiff] = FaceRecognizer(testFile,filename)\n",
        "      i+=1\n",
        "      if(TypeOfTest=='normal'):\n",
        "        if(sameOrDiff=='same'):\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal+=distance\n",
        "        else:\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal_different+=distance\n",
        "      elif(TypeOfTest == 'lowEncrypted'):\n",
        "        if(sameOrDiff == 'same'):\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted+=distance\n",
        "        else:\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted_different+=distance\n",
        "      else:\n",
        "        if(sameOrDiff == 'same'):\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted+=distance\n",
        "        else:\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted_different+=distance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "facenet_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\n",
            "To: /root/.deepface/weights/facenet_weights.h5\n",
            "100%|██████████| 92.2M/92.2M [00:01<00:00, 64.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "AQ8lqCgf1IRp",
        "outputId": "e63d3d05-9d72-4a29-a57f-a25242a751c9"
      },
      "source": [
        "plt.figure(1)\n",
        "objects = ('Normal', 'Low Encrypted','High Encrypted')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [distances_normal/240,distances_lowEncrypted/240,distances_highEncrypted/240]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('Distances Same Person Before Enhancement')\n",
        "plt.figure(2)\n",
        "performance_different_persons = [distances_normal_different/240,distances_lowEncrypted_different/240,distances_highEncrypted_different/240]\n",
        "plt.bar(y_pos, performance_different_persons, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('Distances Different Persons Before Enhancement')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lK0TVrRMAZP"
      },
      "source": [
        "# Enhancement Part & Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import PIL\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Jaa3SZTHokM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_images(path):\n",
        "    base_images_list=list()\n",
        "    names_base=list()\n",
        "    for subdir, dirs, files in os.walk(path):\n",
        "                        dirs.sort()\n",
        "                        os.chdir(subdir)\n",
        "                        for file in files:\n",
        "                            if \"j2k\" not in file: \n",
        "                              names_base.append(file.split('.')[0])\n",
        "                            # load and resize the image\n",
        "                              image = load_img(subdir+'/'+file,target_size=(256,256))\n",
        "                              image_array = img_to_array(image)\n",
        "                              base_images_list.append(image_array)\n",
        "                        return base_images_list ,names_base"
      ],
      "metadata": {
        "id": "YCYQTB5_Z6Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_encrypted_image(path,names_base):\n",
        "    counter=0\n",
        "    encrypted_images_list=list()\n",
        "    for subdir, dirs, files in os.walk(path):\n",
        "                        dirs.sort()\n",
        "                        os.chdir(subdir)\n",
        "                        for file in files:\n",
        "                            if \"j2k_r-W4-O6\" in file: \n",
        "                            # load and resize the image\n",
        "                              image = load_img(subdir+'/'+names_base[counter]+'_j2k_r-W4-O6.png',target_size=(256,256))\n",
        "                              image_array = img_to_array(image)\n",
        "                              encrypted_images_list.append(image_array)\n",
        "                              counter+=1\n",
        "                        return encrypted_images_list"
      ],
      "metadata": {
        "id": "t4H_kn3LZ8dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #load real dataset\n",
        "real_data_array , names_base=load_base_images('/content/gdrive/MyDrive/Final_Test/')\n",
        "real_data_array=[np.asarray((real_data_array), dtype=np.float)]\n",
        "# load Encrypted-L dataset\n",
        "encrypted_data_array=[np.asarray(load_encrypted_image('/content/gdrive/MyDrive/Final_Test/',names_base), dtype=np.float)]\n",
        "print(np.asarray(real_data_array).shape)\n",
        "print(np.asarray(encrypted_data_array).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "x=0\n",
        "merged_images=[]\n",
        "for img in real_data_array[0]:\n",
        "  #Read the two images\n",
        "  image1 = Image.fromarray(np.uint8(real_data_array[0][x])).convert('RGB')\n",
        "  image2 = Image.fromarray(np.uint8(encrypted_data_array[0][x])).convert('RGB')\n",
        "  #resize, first image\n",
        "  image1_size = image1.size\n",
        "  image2_size = image2.size\n",
        "  new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n",
        "  new_image.paste(image1,(0,0))\n",
        "  new_image.paste(image2,(image1_size[0],0))\n",
        "  img_saved=np.array(new_image)\n",
        "  x=x+1\n",
        "  merged_images.append(img_saved)\n",
        "print(np.asarray(merged_images).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "def load(image_file):\n",
        "    w = tf.shape(image_file)[1]  \n",
        "    w = w // 2\n",
        "    input_image = image_file[:, w:, :]\n",
        "    real_image = image_file[:, :w, :]\n",
        "    # Convert both images to float32 tensors\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    return input_image, real_image\n",
        "# The facade training set\n",
        "BUFFER_SIZE = 80\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return input_image, real_image\n",
        "def random_crop(input_image, real_image):\n",
        "\n",
        "    print(IMG_HEIGHT)\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return cropped_image[0], cropped_image[1]\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "# Normalizing the images to [-1, 1]\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "  return input_image, real_image\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "  # Resizing to 142x142\n",
        "  input_image, real_image = resize(input_image, real_image,  286, 286)\n",
        "  # Random cropping back to 112x112\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # Random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "  return input_image, real_image\n",
        "[inp , re] = load(merged_images[0]) \n",
        "BATCH_SIZE = 1\n",
        "def load_image_train(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "  return input_image, real_image\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "def load_image_test(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = resize(input_image, real_image,IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  return input_image, real_image\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "OUTPUT_CHANNELS = 3\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                            kernel_initializer=initializer, use_bias=False))\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "  return result\n",
        "down_model = downsample(3, 4)\n",
        "down_result = down_model(tf.expand_dims(inp, 0))\n",
        "print (down_result.shape,'shape')\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "  return result\n",
        "up_model = upsample(3, 4)\n",
        "up_result = up_model(down_result)\n",
        "print (up_result.shape,'shape up')\n",
        "def Generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "    down_stack = [\n",
        "      downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
        "      downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
        "      downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
        "      downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
        "      downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
        "      downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
        "      downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
        "      downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
        "    ]\n",
        "    up_stack = [\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
        "      upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
        "      upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
        "      upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
        "      upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                          strides=2,\n",
        "                                          padding='same',\n",
        "                                          kernel_initializer=initializer,\n",
        "                                          activation='tanh')  # (batch_size, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "      x = down(x)\n",
        "      skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "      x = up(x)\n",
        "      x = tf.keras.layers.Concatenate()([x, skip])\n",
        "    x = last(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "LAMBDA = 100\n",
        "# ~ -------------------- ~~  -------------------------#\n",
        "generator = Generator()\n",
        "gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # Mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss, gan_loss, l1_loss\n",
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "discriminator = Discriminator()\n",
        "disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
        "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/Biometric/training_checkpoints_r'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "def generate_images(model, test_input, tar,number):\n",
        "    prediction = model(test_input, training=True)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "    print(type(prediction[0]))\n",
        "    # g = tf.Graph()\n",
        "    # IM_HEIGHT  = 112\n",
        "    # IM_WIDTH = 112  \n",
        "    # with g.as_default():\n",
        "    #   inp = tf.Variable(prediction[0])\n",
        "    #   reshape1 = tf.reshape(prediction[0], [IM_WIDTH, IM_HEIGHT, -1])\n",
        "    #   sliced = tf.slice(reshape1, [0,0,0], [ IM_WIDTH, IM_HEIGHT,1])\n",
        "    #   reshaped = tf.reshape(sliced, [IM_HEIGHT, IM_WIDTH, 1])\n",
        "    #   encoded = tf.image.encode_png(tf.image.convert_image_dtype(reshaped,tf.uint16))\n",
        "    #   outputfile = tf.write_file('/content/gdrive/MyDrive/Final_test_enhanced/'+str(number)+'_j2k_r-W4-O6.png', encoded)\n",
        "    #   with tf.Session() as sess:\n",
        "    #     sess.run(tf.global_variables_initializer())\n",
        "    #     sess.run(outputfile)\n",
        "    # image = Image.fromarray(np.asarray(prediction[0]))\n",
        "    # new_width  = 112\n",
        "    # new_height = 112\n",
        "    # image = image.resize((new_width, new_height), Image.ANTIALIAS)\n",
        "    # image_path='/content/gdrive/MyDrive/Final_test_enhanced/'+str(number)+'_j2k_r-W4-O6.png'\n",
        "    # image.save(image_path, format='PNG')\n",
        "    plt.imshow(prediction[0] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    # plt.savefig('/content/gdrive/MyDrive/Final_test_enhanced/'+str(number)+'_j2k_r-W4-O6.png')\n",
        "    for i in range(3):\n",
        "      plt.subplot(1, 3, i+1)\n",
        "      plt.title(title[i])\n",
        "      # Getting the pixel values in the [0, 1] range to plot.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "    plt.show()\n",
        "!ls {checkpoint_dir}\n",
        "#Restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "# Run the trained model on a few examples from the test set\n",
        "number=0\n",
        "for inp, tar in train_dataset.take(80):\n",
        "  number=number+1\n",
        "  generate_images(generator, inp, tar,number)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SAHnjPKUWCfA",
        "outputId": "32c853ff-469a-47d1-9b86-3d61ba9cdd7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_images(path):\n",
        "  base_images_list=list()\n",
        "  names_base=list()\n",
        "  for subdir, dirs, files in os.walk(path):\n",
        "                      dirs.sort()\n",
        "                      os.chdir(subdir)\n",
        "                      for file in files:\n",
        "                          if \"j2k\" not in file: \n",
        "                            names_base.append(file.split('.')[0])\n",
        "                          # load and resize the image\n",
        "                            image = load_img(subdir+'/'+file,target_size=(256,256))\n",
        "                            image_array = img_to_array(image)\n",
        "                            base_images_list.append(image_array)\n",
        "                      return base_images_list ,names_base\n",
        "def load_encrypted_image(path,names_base):\n",
        "  counter=0\n",
        "  encrypted_images_list=list()\n",
        "  for subdir, dirs, files in os.walk(path):\n",
        "                      dirs.sort()\n",
        "                      os.chdir(subdir)\n",
        "                      for file in files:\n",
        "                          if \"j2k_l-W4-O6\" in file: \n",
        "                          # load and resize the image\n",
        "                            image = load_img(subdir+'/'+names_base[counter]+'_j2k_l-W4-O6.png',target_size=(256,256))\n",
        "                            image_array = img_to_array(image)\n",
        "                            encrypted_images_list.append(image_array)\n",
        "                            counter+=1\n",
        "                      return encrypted_images_list\n",
        "  #load real dataset\n",
        "real_data_array , names_base=load_base_images('/content/gdrive/MyDrive/Final_Test/')\n",
        "real_data_array=[np.asarray((real_data_array), dtype=np.float)]\n",
        "# load Encrypted-L dataset\n",
        "encrypted_data_array=[np.asarray(load_encrypted_image('/content/gdrive/MyDrive/Final_Test/',names_base), dtype=np.float)]\n",
        "print(np.asarray(real_data_array).shape)\n",
        "print(np.asarray(encrypted_data_array).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "x=0\n",
        "merged_images=[]\n",
        "for img in real_data_array[0]:\n",
        "  #Read the two images\n",
        "  image1 = Image.fromarray(np.uint8(real_data_array[0][x])).convert('RGB')\n",
        "  image2 = Image.fromarray(np.uint8(encrypted_data_array[0][x])).convert('RGB')\n",
        "  #resize, first image\n",
        "  image1_size = image1.size\n",
        "  image2_size = image2.size\n",
        "  new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n",
        "  new_image.paste(image1,(0,0))\n",
        "  new_image.paste(image2,(image1_size[0],0))\n",
        "  img_saved=np.array(new_image)\n",
        "  x=x+1\n",
        "  merged_images.append(img_saved)\n",
        "print(np.asarray(merged_images).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "def load(image_file):\n",
        "    w = tf.shape(image_file)[1]  \n",
        "    w = w // 2\n",
        "    input_image = image_file[:, w:, :]\n",
        "    real_image = image_file[:, :w, :]\n",
        "    # Convert both images to float32 tensors\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    return input_image, real_image\n",
        "# The facade training set\n",
        "BUFFER_SIZE = 80\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return input_image, real_image\n",
        "def random_crop(input_image, real_image):\n",
        "\n",
        "    print(IMG_HEIGHT)\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return cropped_image[0], cropped_image[1]\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "# Normalizing the images to [-1, 1]\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "  return input_image, real_image\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "  # Resizing to 142x142\n",
        "  input_image, real_image = resize(input_image, real_image,  286, 286)\n",
        "  # Random cropping back to 112x112\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # Random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "  return input_image, real_image\n",
        "[inp , re] = load(merged_images[0]) \n",
        "BATCH_SIZE = 1\n",
        "def load_image_train(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "  return input_image, real_image\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "def load_image_test(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = resize(input_image, real_image,IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  return input_image, real_image\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "OUTPUT_CHANNELS = 3\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                            kernel_initializer=initializer, use_bias=False))\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "  return result\n",
        "down_model = downsample(3, 4)\n",
        "down_result = down_model(tf.expand_dims(inp, 0))\n",
        "print (down_result.shape,'shape')\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "  return result\n",
        "up_model = upsample(3, 4)\n",
        "up_result = up_model(down_result)\n",
        "def Generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "    down_stack = [\n",
        "      downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
        "      downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
        "      downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
        "      downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
        "      downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
        "      downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
        "      downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
        "      downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
        "    ]\n",
        "    up_stack = [\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
        "      upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
        "      upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
        "      upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
        "      upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                          strides=2,\n",
        "                                          padding='same',\n",
        "                                          kernel_initializer=initializer,\n",
        "                                          activation='tanh')  # (batch_size, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "      x = down(x)\n",
        "      skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "      x = up(x)\n",
        "      x = tf.keras.layers.Concatenate()([x, skip])\n",
        "    x = last(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "LAMBDA = 100\n",
        "# ~ -------------------- ~~  -------------------------#\n",
        "generator = Generator()\n",
        "gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # Mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss, gan_loss, l1_loss\n",
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "discriminator = Discriminator()\n",
        "disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
        "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/Biometric/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "def generate_images(model, test_input, tar,number):\n",
        "    prediction = model(test_input, training=True)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "    plt.imshow(prediction[0] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    plt.savefig('/content/gdrive/MyDrive/enhanced_l/'+str(number)+'_j2k_l-W4-O6.png')\n",
        "    for i in range(3):\n",
        "      plt.subplot(1, 3, i+1)\n",
        "      plt.title(title[i])\n",
        "      # Getting the pixel values in the [0, 1] range to plot.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "    plt.show()\n",
        "!ls {checkpoint_dir}\n",
        "#Restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "# Run the trained model on a few examples from the test set\n",
        "number=0\n",
        "for inp, tar in train_dataset.take(80):\n",
        "  number=number+1\n",
        "  generate_images(generator, inp, tar,number)"
      ],
      "metadata": {
        "id": "bqReAQvonXVx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17eaf714-9f48-4865-b496-b91f960bb8fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_images(path):\n",
        "  base_images_list=list()\n",
        "  names_base=list()\n",
        "  for subdir, dirs, files in os.walk(path):\n",
        "                      dirs.sort()\n",
        "                      os.chdir(subdir)\n",
        "                      for file in files:\n",
        "                          if \"j2k\" not in file: \n",
        "                            names_base.append(file.split('.')[0])\n",
        "                          # load and resize the image\n",
        "                            image = load_img(subdir+'/'+file,target_size=(256,256))\n",
        "                            image_array = img_to_array(image)\n",
        "                            base_images_list.append(image_array)\n",
        "                      return base_images_list ,names_base\n",
        "def load_encrypted_image(path,names_base):\n",
        "  counter=0\n",
        "  encrypted_images_list=list()\n",
        "  for subdir, dirs, files in os.walk(path):\n",
        "                      dirs.sort()\n",
        "                      os.chdir(subdir)\n",
        "                      for file in files:\n",
        "                          if \"j2k_l-W4-O6\" in file: \n",
        "                          # load and resize the image\n",
        "                            image = load_img(subdir+'/'+names_base[counter]+'_j2k_l-W4-O6.png',target_size=(256,256))\n",
        "                            image_array = img_to_array(image)\n",
        "                            encrypted_images_list.append(image_array)\n",
        "                            counter+=1\n",
        "                      return encrypted_images_list\n",
        "  #load real dataset\n",
        "real_data_array , names_base=load_base_images('/content/gdrive/MyDrive/Final_Test/')\n",
        "real_data_array=[np.asarray((real_data_array), dtype=np.float)]\n",
        "# load Encrypted-L dataset\n",
        "encrypted_data_array=[np.asarray(load_encrypted_image('/content/gdrive/MyDrive/Final_Test/',names_base), dtype=np.float)]\n",
        "print(np.asarray(real_data_array).shape)\n",
        "print(np.asarray(encrypted_data_array).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "x=0\n",
        "merged_images=[]\n",
        "for img in real_data_array[0]:\n",
        "  #Read the two images\n",
        "  image1 = Image.fromarray(np.uint8(real_data_array[0][x])).convert('RGB')\n",
        "  image2 = Image.fromarray(np.uint8(encrypted_data_array[0][x])).convert('RGB')\n",
        "  #resize, first image\n",
        "  image1_size = image1.size\n",
        "  image2_size = image2.size\n",
        "  new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n",
        "  new_image.paste(image1,(0,0))\n",
        "  new_image.paste(image2,(image1_size[0],0))\n",
        "  img_saved=np.array(new_image)\n",
        "  x=x+1\n",
        "  merged_images.append(img_saved)\n",
        "print(np.asarray(merged_images).shape)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "def load(image_file):\n",
        "    w = tf.shape(image_file)[1]  \n",
        "    w = w // 2\n",
        "    input_image = image_file[:, w:, :]\n",
        "    real_image = image_file[:, :w, :]\n",
        "    # Convert both images to float32 tensors\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    return input_image, real_image\n",
        "# The facade training set\n",
        "BUFFER_SIZE = 80\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return input_image, real_image\n",
        "def random_crop(input_image, real_image):\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return cropped_image[0], cropped_image[1]\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "# Normalizing the images to [-1, 1]\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "  return input_image, real_image\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "  # Resizing to 142x142\n",
        "  input_image, real_image = resize(input_image, real_image,  286, 286)\n",
        "  # Random cropping back to 112x112\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # Random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "  return input_image, real_image\n",
        "[inp , re] = load(merged_images[0]) \n",
        "BATCH_SIZE = 1\n",
        "def load_image_train(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "  return input_image, real_image\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "def load_image_test(image_file):\n",
        "  input_image, real_image = load(image_file)\n",
        "  input_image, real_image = resize(input_image, real_image,IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  return input_image, real_image\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(merged_images)\n",
        "# !-------------------- !! ----------------------------------- #\n",
        "OUTPUT_CHANNELS = 3\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                            kernel_initializer=initializer, use_bias=False))\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "  return result\n",
        "down_model = downsample(3, 4)\n",
        "down_result = down_model(tf.expand_dims(inp, 0))\n",
        "print (down_result.shape,'shape')\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "  return result\n",
        "up_model = upsample(3, 4)\n",
        "up_result = up_model(down_result)\n",
        "def Generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "    down_stack = [\n",
        "      downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
        "      downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
        "      downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
        "      downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
        "      downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
        "      downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
        "      downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
        "      downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
        "    ]\n",
        "    up_stack = [\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
        "      upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
        "      upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
        "      upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
        "      upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                          strides=2,\n",
        "                                          padding='same',\n",
        "                                          kernel_initializer=initializer,\n",
        "                                          activation='tanh')  # (batch_size, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "      x = down(x)\n",
        "      skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "      x = up(x)\n",
        "      x = tf.keras.layers.Concatenate()([x, skip])\n",
        "    x = last(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "LAMBDA = 100\n",
        "# ~ -------------------- ~~  -------------------------#\n",
        "generator = Generator()\n",
        "gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # Mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss, gan_loss, l1_loss\n",
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "discriminator = Discriminator()\n",
        "disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
        "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "plt.colorbar()\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "checkpoint_dir = '/content/gdrive/MyDrive/Biometric/training_checkpoints_l'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "def generate_images(model, test_input, tar,number):\n",
        "    prediction = model(test_input, training=True)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "    plt.imshow(prediction[0] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "    plt.savefig('/content/gdrive/MyDrive/enhanced_l_last/'+str(number)+'_j2k_l-W4-O6.png')\n",
        "    for i in range(3):\n",
        "      plt.subplot(1, 3, i+1)\n",
        "      plt.title(title[i])\n",
        "      # Getting the pixel values in the [0, 1] range to plot.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "    plt.show()\n",
        "!ls {checkpoint_dir}\n",
        "#Restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "# Run the trained model on a few examples from the test set\n",
        "number=0\n",
        "for inp, tar in train_dataset.take(80):\n",
        "  number=number+1\n",
        "  generate_images(generator, inp, tar,number)"
      ],
      "metadata": {
        "id": "5P8KGPxhnKfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26713815-a54f-4e55-963f-c6e1475e7ca9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FaceRecognizerEnhanced(filename1,filename2):\n",
        "  folder = './gdrive/MyDrive/Final_test_enhanced/'\n",
        "  # path\n",
        "  filenameTest = folder + filename1\n",
        "  filenameVerify= folder + filename2\n",
        "  if filename2.find(\"j2k_r\") == -1 and filename2.find(\"j2k\") == -1:\n",
        "    TypeOfTest='normal'\n",
        "  else:\n",
        "    if(filename2.find(\"j2k_r\") == -1):\n",
        "          TypeOfTest='hardEncrypted'\n",
        "    else:\n",
        "          TypeOfTest='lowEncrypted'\n",
        "\n",
        "  detected=DeepFace.verify(img1_path=filenameTest,img2_path=filenameVerify,model_name='Facenet',enforce_detection=False)\n",
        "  if(filename1.split('_')[0] ==  filename2.split('_')[0]):\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,1,detected['distance'],'same')\n",
        "    else:\n",
        "          return (TypeOfTest,-1,0,'same')\n",
        "  else:\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,-1,0,'different')\n",
        "    else:\n",
        "          return (TypeOfTest,1,detected['distance'],'different')\n"
      ],
      "metadata": {
        "id": "O1hwxKi6nKiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
        "# specify folder to plot\n",
        "filename1_normal='501194_490544.jpg'\n",
        "filename2_normal='501195_490571.jpg'\n",
        "array_test_images=[filename1_normal,filename2_normal]\n",
        "folder = './gdrive/MyDrive/Final_test_enhanced/'\n",
        "i = 1\n",
        "x_axis=0\n",
        "normal_y_axis=0\n",
        "lowEncrypted_y_axis=0\n",
        "distances_normal=0\n",
        "distances_normal_different=0\n",
        "distances_lowEncrypted=0\n",
        "distances_lowEncrypted_different=0\n",
        "highEncrypted_y_axis=0\n",
        "distances_highEncrypted=0\n",
        "distances_highEncrypted_different=0\n",
        "for testFile in array_test_images:\n",
        "    # enumerate files\n",
        "  for filename in listdir(folder):\n",
        "    # get prediction\n",
        "    if(filename != '.ipynb_checkpoints'):\n",
        "      [TypeOfTest,value,distance,sameOrDiff] = FaceRecognizerEnhanced(testFile,filename)\n",
        "      i+=1\n",
        "      if(TypeOfTest=='normal'):\n",
        "        if(sameOrDiff=='same'):\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal+=distance\n",
        "        else:\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal_different+=distance\n",
        "      elif(TypeOfTest == 'lowEncrypted'):\n",
        "        if(sameOrDiff == 'same'):\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted+=distance\n",
        "        else:\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted_different+=distance\n",
        "      else:\n",
        "        if(sameOrDiff == 'same'):\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted+=distance\n",
        "        else:\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted_different+=distance\n"
      ],
      "metadata": {
        "id": "8kKTIkSanKkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "objects = ('Normal', 'Low Encrypted','High Encrypted')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [distances_normal/240,distances_lowEncrypted/240,distances_highEncrypted/240]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('Pix2Pix Gan Distances Same Person After Enhancement')\n",
        "plt.figure(2)\n",
        "performance_different_persons = [distances_normal_different/240,distances_lowEncrypted_different/240,distances_highEncrypted_different/240]\n",
        "plt.bar(y_pos, performance_different_persons, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('Pix2Pix Gan Distances Different Persons After Enhancement')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dX2zRiIdnKnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "1f16f66a-8ff1-47a2-87cb-069917ce2b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def FaceRecognizerEnhanced(filename1,filename2):\n",
        "  folder = './gdrive/MyDrive/CycleGan_FinalTest/'\n",
        "  # path\n",
        "  filenameTest = folder + filename1\n",
        "  filenameVerify= folder + filename2\n",
        "  if filename2.find(\"j2k_r\") == -1 and filename2.find(\"j2k\") == -1:\n",
        "    TypeOfTest='normal'\n",
        "  else:\n",
        "    if(filename2.find(\"j2k_r\") == -1):\n",
        "          TypeOfTest='hardEncrypted'\n",
        "    else:\n",
        "          TypeOfTest='lowEncrypted'\n",
        "\n",
        "  detected=DeepFace.verify(img1_path=filenameTest,img2_path=filenameVerify,model_name='Facenet',enforce_detection=False)\n",
        "  if(filename1.split('_')[0] ==  filename2.split('_')[0]):\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,1,detected['distance'],'same')\n",
        "    else:\n",
        "          return (TypeOfTest,-1,0,'same')\n",
        "  else:\n",
        "    if(detected['verified']):\n",
        "          return (TypeOfTest,-1,0,'different')\n",
        "    else:\n",
        "          return (TypeOfTest,1,detected['distance'],'different')"
      ],
      "metadata": {
        "id": "COAzXvDSnKqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate face detection on 5 Celebrity Faces Dataset\n",
        "# specify folder to plot\n",
        "filename1_normal='501194_490544.jpg'\n",
        "filename2_normal='501195_490571.jpg'\n",
        "array_test_images=[filename1_normal,filename2_normal]\n",
        "folder = './gdrive/MyDrive/CycleGan_FinalTest/'\n",
        "i = 1\n",
        "x_axis=0\n",
        "normal_y_axis=0\n",
        "lowEncrypted_y_axis=0\n",
        "distances_normal=0\n",
        "distances_normal_different=0\n",
        "distances_lowEncrypted=0\n",
        "distances_lowEncrypted_different=0\n",
        "highEncrypted_y_axis=0\n",
        "distances_highEncrypted=0\n",
        "distances_highEncrypted_different=0\n",
        "for testFile in array_test_images:\n",
        "    # enumerate files\n",
        "  for filename in listdir(folder):\n",
        "    # get prediction\n",
        "    if(filename != '.ipynb_checkpoints'):\n",
        "      [TypeOfTest,value,distance,sameOrDiff] = FaceRecognizerEnhanced(testFile,filename)\n",
        "      i+=1\n",
        "      if(TypeOfTest=='normal'):\n",
        "        if(sameOrDiff=='same'):\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal+=distance\n",
        "        else:\n",
        "                  normal_y_axis+=value\n",
        "                  distances_normal_different+=distance\n",
        "      elif(TypeOfTest == 'lowEncrypted'):\n",
        "        if(sameOrDiff == 'same'):\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted+=distance\n",
        "        else:\n",
        "          lowEncrypted_y_axis+=value\n",
        "          distances_lowEncrypted_different+=distance\n",
        "      else:\n",
        "        if(sameOrDiff == 'same'):\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted+=distance\n",
        "        else:\n",
        "           highEncrypted_y_axis+=value\n",
        "           distances_highEncrypted_different+=distance"
      ],
      "metadata": {
        "id": "yDUXhGTkCm_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "objects = ('Normal', 'Low Encrypted','High Encrypted')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [distances_normal/240,distances_lowEncrypted/240,distances_highEncrypted/240]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('CycleGan Distances Same Person After Enhancement')\n",
        "plt.figure(2)\n",
        "performance_different_persons = [distances_normal_different/240,distances_lowEncrypted_different/240,distances_highEncrypted_different/240]\n",
        "plt.bar(y_pos, performance_different_persons, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Distances')\n",
        "plt.title('CycleGan Distances Different Persons After Enhancement')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "3FgKhV33Cp8_",
        "outputId": "95720789-4968-45ce-dbbc-351222d99506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}